{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet Machine Learning\n",
    "- Bruno Dumas (p1100740)\n",
    "- Romy Ratolojanahary (p1210599)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Présentation du sujet\n",
    "\n",
    "Le sujet de ce projet est proposé sur le site Kaggle par le site Quora. Il s'agit d'un forum de questions-réponses sur tous les sujets.\n",
    "Quora désire identifier les questions dupliquées. Le dataset contient des paires de questions.\n",
    "Le but du projet est donc de définir si deux questions sont similaires ou non.\n",
    "\n",
    "Les données sont téléchargeables à l'url suivante : https://www.kaggle.com/c/quora-question-pairs/data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/bruno/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/bruno/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/bruno/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]     /home/bruno/nltk_data...\n",
      "[nltk_data]   Package maxent_treebank_pos_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/bruno/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(threshold=np.nan)\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings('ignore')\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "for lib in ['stopwords', 'wordnet', 'punkt', 'maxent_treebank_pos_tagger', 'averaged_perceptron_tagger']: \n",
    "    nltk.download(lib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# On importe les données\n",
    "quora = pd.read_csv('./train.csv', delimiter=',')\n",
    "\n",
    "# Réduction de la taille de la base pour accélérer les traitements\n",
    "from sklearn.model_selection import train_test_split\n",
    "quora, _ = train_test_split(quora, test_size = 0.9)\n",
    "quora = quora.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>33</td>\n",
       "      <td>34</td>\n",
       "      <td>What does manipulation mean?</td>\n",
       "      <td>What does manipulation means?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>39</td>\n",
       "      <td>40</td>\n",
       "      <td>Which is the best digital marketing institutio...</td>\n",
       "      <td>Which is the best digital marketing institute ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>43</td>\n",
       "      <td>44</td>\n",
       "      <td>What's causing someone to be jealous?</td>\n",
       "      <td>What can I do to avoid being jealous of someone?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>55</td>\n",
       "      <td>56</td>\n",
       "      <td>Does society place too much importance on sports?</td>\n",
       "      <td>How do sports contribute to the society?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>63</td>\n",
       "      <td>64</td>\n",
       "      <td>What are some special cares for someone with a...</td>\n",
       "      <td>How can I keep my nose from getting stuffy at ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>75</td>\n",
       "      <td>76</td>\n",
       "      <td>When a girlfriend asks her boyfriend \"Why did ...</td>\n",
       "      <td>My girlfriend said that we should end this bec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>77</td>\n",
       "      <td>78</td>\n",
       "      <td>How do we prepare for UPSC?</td>\n",
       "      <td>How do I prepare for civil service?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>56</td>\n",
       "      <td>113</td>\n",
       "      <td>114</td>\n",
       "      <td>Who is israil friend?</td>\n",
       "      <td>Is my boyfriend lying about his true feelings ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>59</td>\n",
       "      <td>119</td>\n",
       "      <td>120</td>\n",
       "      <td>What are the best ways to learn French?</td>\n",
       "      <td>How do I learn french genders?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>70</td>\n",
       "      <td>141</td>\n",
       "      <td>142</td>\n",
       "      <td>What are the types of immunity?</td>\n",
       "      <td>What are the different types of immunity in ou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  qid1  qid2                                          question1  \\\n",
       "16  16    33    34                       What does manipulation mean?   \n",
       "19  19    39    40  Which is the best digital marketing institutio...   \n",
       "21  21    43    44              What's causing someone to be jealous?   \n",
       "27  27    55    56  Does society place too much importance on sports?   \n",
       "31  31    63    64  What are some special cares for someone with a...   \n",
       "37  37    75    76  When a girlfriend asks her boyfriend \"Why did ...   \n",
       "38  38    77    78                        How do we prepare for UPSC?   \n",
       "56  56   113   114                              Who is israil friend?   \n",
       "59  59   119   120            What are the best ways to learn French?   \n",
       "70  70   141   142                    What are the types of immunity?   \n",
       "\n",
       "                                            question2  is_duplicate  \n",
       "16                      What does manipulation means?             1  \n",
       "19  Which is the best digital marketing institute ...             0  \n",
       "21   What can I do to avoid being jealous of someone?             0  \n",
       "27           How do sports contribute to the society?             0  \n",
       "31  How can I keep my nose from getting stuffy at ...             1  \n",
       "37  My girlfriend said that we should end this bec...             0  \n",
       "38                How do I prepare for civil service?             1  \n",
       "56  Is my boyfriend lying about his true feelings ...             0  \n",
       "59                     How do I learn french genders?             0  \n",
       "70  What are the different types of immunity in ou...             0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quora.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistique Descriptive\n",
    "\n",
    "Chaque observation comporte 2 paires de questions. Les autres colonnes sont l'id de l'observation, l'id de la question 1, l'id de la question 2 et enfin un booléen 'is_duplicate' qui vaut 1 si les questions sont similaires, 0 sinon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_obs  = 40429\n",
      "n_obs sans duplicats  = 40429\n",
      "n_obs sans NA  = 40429\n",
      "is_duplicate\n",
      "0    25461\n",
      "1    14968\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEHCAYAAABFroqmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAEURJREFUeJzt3X+snmV9x/H3R4oMhziErukKWCY1W2ERR1OZuo2NZVRd\nBi7g6hZhrqEuoNFEF8Fk0WVrAlmUjDlYcDB+xPFjqKNRwDDUON34cVC0FEROBAZNhQoMdAa24nd/\nPNfZnp7rlHN6zrHPgfN+JXee6/ne93Xf3ydp+XD/eJ6mqpAkadhLRt2AJGnhMRwkSR3DQZLUMRwk\nSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLUWTLqBmbrkEMOqZUrV466DUl6Qbnzzju/X1VLp9vuBRsO\nK1euZGxsbNRtSNILSpKHZrKdl5UkSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLUecF+\nCe6FYuXZnx91Cy8qD5771lG3IC0K0545JDksyZeS3JNka5L3tfpHk2xLcldb3jI055wk40nuS3Li\nUP3YJFvauguSpNX3S3JNq9+WZOX8f1RJ0kzN5LLSTuADVbUaOA44K8nqtu78qjqmLTcAtHXrgaOA\ndcCFSfZp218EnAGsasu6Vt8APFlVRwLnA+fN/aNJkmZr2nCoqu1V9fU2/gFwL7DieaacBFxdVc9W\n1QPAOLA2yXLgwKq6taoKuAI4eWjO5W18HXDCxFmFJGnv26Mb0u1yz+uA21rpvUm+leTSJAe12grg\n4aFpj7TaijaeXN9lTlXtBJ4CDp7i+BuTjCUZ27Fjx560LknaAzMOhyQHAJ8G3l9VTzO4RPTzwDHA\nduBjP5EOh1TVxVW1pqrWLF067S/OSpJmaUbhkGRfBsHwqar6DEBVPVpVz1XVj4FPAmvb5tuAw4am\nH9pq29p4cn2XOUmWAK8AHp/NB5Ikzd1MnlYKcAlwb1V9fKi+fGiztwF3t/FmYH17AukIBjeeb6+q\n7cDTSY5r+zwNuH5ozultfArwxXZfQpI0AjP5nsMbgXcCW5Lc1WofBt6R5BiggAeBdwNU1dYk1wL3\nMHjS6ayqeq7NOxO4DNgfuLEtMAifK5OMA08weNpJkjQi04ZDVX0VmOrJoRueZ84mYNMU9THg6Cnq\nzwCnTteLJGnv8OczJEkdw0GS1DEcJEkdw0GS1DEcJEkdw0GS1DEcJEkdw0GS1DEcJEkdw0GS1DEc\nJEkdw0GS1DEcJEkdw0GS1DEcJEkdw0GS1DEcJEkdw0GS1DEcJEkdw0GS1DEcJEkdw0GS1DEcJEkd\nw0GS1DEcJEkdw0GS1DEcJEkdw0GS1DEcJEkdw0GS1DEcJEmdacMhyWFJvpTkniRbk7yv1V+Z5OYk\n97fXg4bmnJNkPMl9SU4cqh+bZEtbd0GStPp+Sa5p9duSrJz/jypJmqmZnDnsBD5QVauB44CzkqwG\nzgZuqapVwC3tPW3deuAoYB1wYZJ92r4uAs4AVrVlXatvAJ6sqiOB84Hz5uGzSZJmadpwqKrtVfX1\nNv4BcC+wAjgJuLxtdjlwchufBFxdVc9W1QPAOLA2yXLgwKq6taoKuGLSnIl9XQecMHFWIUna+/bo\nnkO73PM64DZgWVVtb6u+Byxr4xXAw0PTHmm1FW08ub7LnKraCTwFHLwnvUmS5s+MwyHJAcCngfdX\n1dPD69qZQM1zb1P1sDHJWJKxHTt2/KQPJ0mL1ozCIcm+DILhU1X1mVZ+tF0qor0+1urbgMOGph/a\natvaeHJ9lzlJlgCvAB6f3EdVXVxVa6pqzdKlS2fSuiRpFmbytFKAS4B7q+rjQ6s2A6e38enA9UP1\n9e0JpCMY3Hi+vV2CejrJcW2fp02aM7GvU4AvtrMRSdIILJnBNm8E3glsSXJXq30YOBe4NskG4CHg\n7QBVtTXJtcA9DJ50OquqnmvzzgQuA/YHbmwLDMLnyiTjwBMMnnaSJI3ItOFQVV8Fdvfk0Am7mbMJ\n2DRFfQw4eor6M8Cp0/UiSdo7/Ia0JKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaD\nJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKlj\nOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOtOGQ5JLkzyW\n5O6h2keTbEtyV1veMrTunCTjSe5LcuJQ/dgkW9q6C5Kk1fdLck2r35Zk5fx+REnSnprJmcNlwLop\n6udX1TFtuQEgyWpgPXBUm3Nhkn3a9hcBZwCr2jKxzw3Ak1V1JHA+cN4sP4skaZ5MGw5V9RXgiRnu\n7yTg6qp6tqoeAMaBtUmWAwdW1a1VVcAVwMlDcy5v4+uAEybOKiRJozGXew7vTfKtdtnpoFZbATw8\ntM0jrbaijSfXd5lTVTuBp4CD59CXJGmOlsxy3kXAXwDVXj8G/PF8NbU7STYCGwEOP/zwn/ThpBe1\nlWd/ftQtvKg8eO5bR93CvJrVmUNVPVpVz1XVj4FPAmvbqm3AYUObHtpq29p4cn2XOUmWAK8AHt/N\ncS+uqjVVtWbp0qWzaV2SNAOzCod2D2HC24CJJ5k2A+vbE0hHMLjxfHtVbQeeTnJcu59wGnD90JzT\n2/gU4IvtvoQkaUSmvayU5CrgeOCQJI8AHwGOT3IMg8tKDwLvBqiqrUmuBe4BdgJnVdVzbVdnMnjy\naX/gxrYAXAJcmWScwY3v9fPxwSRJszdtOFTVO6YoX/I8228CNk1RHwOOnqL+DHDqdH1IkvYevyEt\nSeoYDpKkjuEgSeoYDpKkjuEgSeoYDpKkjuEgSeoYDpKkjuEgSeoYDpKkjuEgSeoYDpKkjuEgSeoY\nDpKkjuEgSeoYDpKkjuEgSeoYDpKkjuEgSeoYDpKkjuEgSeoYDpKkjuEgSeoYDpKkjuEgSeoYDpKk\njuEgSeoYDpKkjuEgSeoYDpKkjuEgSeoYDpKkzrThkOTSJI8luXuo9sokNye5v70eNLTunCTjSe5L\ncuJQ/dgkW9q6C5Kk1fdLck2r35Zk5fx+REnSnprJmcNlwLpJtbOBW6pqFXBLe0+S1cB64Kg258Ik\n+7Q5FwFnAKvaMrHPDcCTVXUkcD5w3mw/jCRpfkwbDlX1FeCJSeWTgMvb+HLg5KH61VX1bFU9AIwD\na5MsBw6sqlurqoArJs2Z2Nd1wAkTZxWSpNGY7T2HZVW1vY2/Byxr4xXAw0PbPdJqK9p4cn2XOVW1\nE3gKOHiqgybZmGQsydiOHTtm2bokaTpzviHdzgRqHnqZybEurqo1VbVm6dKle+OQkrQozTYcHm2X\nimivj7X6NuCwoe0ObbVtbTy5vsucJEuAVwCPz7IvSdI8mG04bAZOb+PTgeuH6uvbE0hHMLjxfHu7\nBPV0kuPa/YTTJs2Z2NcpwBfb2YgkaUSWTLdBkquA44FDkjwCfAQ4F7g2yQbgIeDtAFW1Ncm1wD3A\nTuCsqnqu7epMBk8+7Q/c2BaAS4Ark4wzuPG9fl4+mSRp1qYNh6p6x25WnbCb7TcBm6aojwFHT1F/\nBjh1uj4kSXuP35CWJHUMB0lSx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHUMB0lSx3CQ\nJHUMB0lSx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHUM\nB0lSx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHXmFA5JHkyyJcldScZa7ZVJbk5yf3s9\naGj7c5KMJ7kvyYlD9WPbfsaTXJAkc+lLkjQ383Hm8BtVdUxVrWnvzwZuqapVwC3tPUlWA+uBo4B1\nwIVJ9mlzLgLOAFa1Zd089CVJmqWfxGWlk4DL2/hy4OSh+tVV9WxVPQCMA2uTLAcOrKpbq6qAK4bm\nSJJGYK7hUMC/JLkzycZWW1ZV29v4e8CyNl4BPDw095FWW9HGk+uSpBFZMsf5b6qqbUl+Frg5ybeH\nV1ZVJak5HuP/tADaCHD44YfP124lSZPM6cyhqra118eAzwJrgUfbpSLa62Nt823AYUPTD221bW08\nuT7V8S6uqjVVtWbp0qVzaV2S9DxmHQ5JfjrJyyfGwG8DdwObgdPbZqcD17fxZmB9kv2SHMHgxvPt\n7RLU00mOa08pnTY0R5I0AnO5rLQM+Gx76nQJ8I9VdVOSO4Brk2wAHgLeDlBVW5NcC9wD7ATOqqrn\n2r7OBC4D9gdubIskaURmHQ5V9V3gtVPUHwdO2M2cTcCmKepjwNGz7UWSNL/8hrQkqWM4SJI6hoMk\nqWM4SJI6hoMkqWM4SJI6hoMkqWM4SJI6hoMkqWM4SJI6hoMkqWM4SJI6hoMkqWM4SJI6hoMkqWM4\nSJI6hoMkqWM4SJI6hoMkqWM4SJI6hoMkqWM4SJI6hoMkqWM4SJI6hoMkqWM4SJI6hoMkqWM4SJI6\nhoMkqWM4SJI6hoMkqWM4SJI6CyYckqxLcl+S8SRnj7ofSVrMFkQ4JNkH+FvgzcBq4B1JVo+2K0la\nvBZEOABrgfGq+m5V/TdwNXDSiHuSpEVroYTDCuDhofePtJokaQSWjLqBPZFkI7Cxvf1hkvtG2c+L\nzCHA90fdxHRy3qg70Aj4Z3N+vWomGy2UcNgGHDb0/tBW20VVXQxcvLeaWkySjFXVmlH3IU3mn83R\nWCiXle4AViU5IslLgfXA5hH3JEmL1oI4c6iqnUneA3wB2Ae4tKq2jrgtSVq0FkQ4AFTVDcANo+5j\nEfNynRYq/2yOQKpq1D1IkhaYhXLPQZK0gBgOkqSO4SBJ6iyYG9Lae5L8AoOfJ5n4Fvo2YHNV3Tu6\nriQtJJ45LDJJPsTgt6sC3N6WAFf5a7hayJK8a9Q9LCY+rbTIJPkOcFRV/c+k+kuBrVW1ajSdSc8v\nyX9U1eGj7mOx8LLS4vNj4OeAhybVl7d10sgk+dbuVgHL9mYvi53hsPi8H7glyf38/y/hHg4cCbxn\nZF1JA8uAE4EnJ9UD/Nveb2fxMhwWmaq6KclrGPwbGsM3pO+oqudG15kEwOeAA6rqrskrknx577ez\neHnPQZLU8WklSVLHcJAkdQwHveglmdONzCR/lOQTc5j/YJJD5tJLkpOTrJ5tD9KeMhz0oldVbxh1\nDxPm0MvJgOGgvcZw0Itekh+21+VJvpLkriR3J/nV55nzriTfSXI78Mah+mVJTpli38e3fX8+yX1J\n/i5J9/drYvs2/lCSLUm+meTcVjsjyR2t9ukkL0vyBuB3gb9qvb+6LTcluTPJv7afRJHmjY+yajH5\nA+ALVbUpyT7Ay6baKMly4M+BY4GngC8B35jB/tcy+L/7h4CbgN8DrtvNMd7M4PetXl9VP0ryyrbq\nM1X1ybbNXwIbqupvkmwGPldV17V1twB/UlX3J3k9cCHwmzPoUZoRw0GLyR3ApUn2Bf55qmfpm9cD\nX66qHQBJrgFeM4P9315V321zrgLexG7CAfgt4B+q6kcAVfVEqx/dQuFngAMY/NO5u0hyAPAG4J+S\nTJT3m0F/0ox5WUmLRlV9Bfg1Bl/6uyzJabPYzU7a35t22eilw4eYfMhZ7P8y4D1V9UsMzl5+aopt\nXgL8Z1UdM7T84iyOJe2W4aBFI8mrgEfbZZu/B355N5veBvx6koPbWcapQ+seZHC5CQb3AfYdWrc2\nyREtNH4f+OrztHMz8K4kL2u9TVxWejmwvR33D4e2/0FbR1U9DTyQ5NQ2N0le+zzHkvaY4aDF5Hjg\nm0m+weA/3n891UZVtR34KPDvwNeA4X/n4pMMguObwK8A/zW07g7gE237B4DP7q6RqroJ2AyMJbkL\n+GBb9WcMwulrwLeHplwN/GmSbyR5NYPg2ND62Mrg/oU0b/z5DGkeJDke+GBV/c6oe5Hmg2cOkqSO\nZw5a1JLcRv+kzzurasso+pEWCsNBktTxspIkqWM4SJI6hoMkqWM4SJI6hoMkqfO/XVKBN5fxeHEA\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9a499a2f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Nombre de paires de questions\n",
    "n_obs = quora.shape[0]\n",
    "print(\"n_obs  = %d\" %n_obs)\n",
    "\n",
    "# On enlève les duplicats (les paires qui sont présentes plus d'une fois) \n",
    "quora.drop_duplicates(inplace=True)\n",
    "n_obs1 = quora.shape[0]\n",
    "print(\"n_obs sans duplicats  = %d\" %n_obs1)\n",
    "\n",
    "# On enlève les lignes contenant des NaN\n",
    "\n",
    "quora.dropna(inplace=True) \n",
    "n_obs2 = quora.shape[0]\n",
    "print(\"n_obs sans NA  = %d\" %n_obs2)\n",
    "\n",
    "# Proportion de 0 et de 1\n",
    "print(quora.groupby(['is_duplicate']).size())\n",
    "quora.groupby(['is_duplicate']).size().plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ajouter une colonne tokens qui contient les mots tokenisés\n",
    "quora['tokens1'] = quora.question1.apply(lambda x: (nltk.word_tokenize(x)))\n",
    "quora['tokens2'] = quora.question2.apply(lambda x: (nltk.word_tokenize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# On détermine la nature grammaticale des mots \n",
    "quora['tokenspos1'] = quora.tokens1.apply(lambda x: nltk.pos_tag(x))\n",
    "quora['tokenspos2'] = quora.tokens2.apply(lambda x: nltk.pos_tag(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Fonction qui retourne la 'racine' du mot\n",
    "# Si c'est un nom, renvoyer nom générique (singulier), si verbe, renvoyer l'infinitif\n",
    "\n",
    "def lemmatizer(sentence): # Entrée de la forme [(mot1,tag1),(mot2,tag2)....]\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    posVerb = []\n",
    "    for t in sentence:\n",
    "        if t[1][0] == 'V':\n",
    "            posVerb.append(wordnet_lemmatizer.lemmatize(t[0],pos='v'))\n",
    "        else:\n",
    "            posVerb.append(wordnet_lemmatizer.lemmatize(t[0]))\n",
    "    return posVerb    \n",
    "                           \n",
    "quora['lemma1'] = quora.tokenspos1.apply(lambda x: lemmatizer(x))\n",
    "quora['lemma2'] = quora.tokenspos2.apply(lambda x: lemmatizer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>lemma1</th>\n",
       "      <th>lemma2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>What does manipulation mean?</td>\n",
       "      <td>What does manipulation means?</td>\n",
       "      <td>[What, do, manipulation, mean, ?]</td>\n",
       "      <td>[What, do, manipulation, mean, ?]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Which is the best digital marketing institutio...</td>\n",
       "      <td>Which is the best digital marketing institute ...</td>\n",
       "      <td>[Which, be, the, best, digital, marketing, ins...</td>\n",
       "      <td>[Which, be, the, best, digital, marketing, ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>What's causing someone to be jealous?</td>\n",
       "      <td>What can I do to avoid being jealous of someone?</td>\n",
       "      <td>[What, 's, cause, someone, to, be, jealous, ?]</td>\n",
       "      <td>[What, can, I, do, to, avoid, be, jealous, of,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Does society place too much importance on sports?</td>\n",
       "      <td>How do sports contribute to the society?</td>\n",
       "      <td>[Does, society, place, too, much, importance, ...</td>\n",
       "      <td>[How, do, sport, contribute, to, the, society, ?]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>What are some special cares for someone with a...</td>\n",
       "      <td>How can I keep my nose from getting stuffy at ...</td>\n",
       "      <td>[What, be, some, special, care, for, someone, ...</td>\n",
       "      <td>[How, can, I, keep, my, nose, from, get, stuff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>When a girlfriend asks her boyfriend \"Why did ...</td>\n",
       "      <td>My girlfriend said that we should end this bec...</td>\n",
       "      <td>[When, a, girlfriend, ask, her, boyfriend, ``,...</td>\n",
       "      <td>[My, girlfriend, say, that, we, should, end, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>How do we prepare for UPSC?</td>\n",
       "      <td>How do I prepare for civil service?</td>\n",
       "      <td>[How, do, we, prepare, for, UPSC, ?]</td>\n",
       "      <td>[How, do, I, prepare, for, civil, service, ?]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Who is israil friend?</td>\n",
       "      <td>Is my boyfriend lying about his true feelings ...</td>\n",
       "      <td>[Who, be, israil, friend, ?]</td>\n",
       "      <td>[Is, my, boyfriend, lie, about, his, true, fee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>What are the best ways to learn French?</td>\n",
       "      <td>How do I learn french genders?</td>\n",
       "      <td>[What, be, the, best, way, to, learn, French, ?]</td>\n",
       "      <td>[How, do, I, learn, french, gender, ?]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>What are the types of immunity?</td>\n",
       "      <td>What are the different types of immunity in ou...</td>\n",
       "      <td>[What, be, the, type, of, immunity, ?]</td>\n",
       "      <td>[What, be, the, different, type, of, immunity,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question1  \\\n",
       "16                       What does manipulation mean?   \n",
       "19  Which is the best digital marketing institutio...   \n",
       "21              What's causing someone to be jealous?   \n",
       "27  Does society place too much importance on sports?   \n",
       "31  What are some special cares for someone with a...   \n",
       "37  When a girlfriend asks her boyfriend \"Why did ...   \n",
       "38                        How do we prepare for UPSC?   \n",
       "56                              Who is israil friend?   \n",
       "59            What are the best ways to learn French?   \n",
       "70                    What are the types of immunity?   \n",
       "\n",
       "                                            question2  \\\n",
       "16                      What does manipulation means?   \n",
       "19  Which is the best digital marketing institute ...   \n",
       "21   What can I do to avoid being jealous of someone?   \n",
       "27           How do sports contribute to the society?   \n",
       "31  How can I keep my nose from getting stuffy at ...   \n",
       "37  My girlfriend said that we should end this bec...   \n",
       "38                How do I prepare for civil service?   \n",
       "56  Is my boyfriend lying about his true feelings ...   \n",
       "59                     How do I learn french genders?   \n",
       "70  What are the different types of immunity in ou...   \n",
       "\n",
       "                                               lemma1  \\\n",
       "16                  [What, do, manipulation, mean, ?]   \n",
       "19  [Which, be, the, best, digital, marketing, ins...   \n",
       "21     [What, 's, cause, someone, to, be, jealous, ?]   \n",
       "27  [Does, society, place, too, much, importance, ...   \n",
       "31  [What, be, some, special, care, for, someone, ...   \n",
       "37  [When, a, girlfriend, ask, her, boyfriend, ``,...   \n",
       "38               [How, do, we, prepare, for, UPSC, ?]   \n",
       "56                       [Who, be, israil, friend, ?]   \n",
       "59   [What, be, the, best, way, to, learn, French, ?]   \n",
       "70             [What, be, the, type, of, immunity, ?]   \n",
       "\n",
       "                                               lemma2  \n",
       "16                  [What, do, manipulation, mean, ?]  \n",
       "19  [Which, be, the, best, digital, marketing, ins...  \n",
       "21  [What, can, I, do, to, avoid, be, jealous, of,...  \n",
       "27  [How, do, sport, contribute, to, the, society, ?]  \n",
       "31  [How, can, I, keep, my, nose, from, get, stuff...  \n",
       "37  [My, girlfriend, say, that, we, should, end, t...  \n",
       "38      [How, do, I, prepare, for, civil, service, ?]  \n",
       "56  [Is, my, boyfriend, lie, about, his, true, fee...  \n",
       "59             [How, do, I, learn, french, gender, ?]  \n",
       "70  [What, be, the, different, type, of, immunity,...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quora[['question1','question2','lemma1','lemma2']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "# Retrait des stopwords des questions\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "# Nous allons retirer quelques stopwords et ajouter les signes de ponctuation\n",
    "remove_words = ['not', 't', 'why', 'when', 'who', 'which', 'where', 'what', 'how', 'i', 'me', \n",
    "                'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', \n",
    "                'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', \n",
    "                'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves']\n",
    "add_words = []\n",
    "add_words.extend([char for char in string.punctuation])\n",
    "for w in remove_words:\n",
    "    stopwords.remove(w)\n",
    "for w in add_words:\n",
    "    stopwords.append(w)\n",
    "\n",
    "def remove_stopwords(sentence):\n",
    "    out = []\n",
    "    for t in sentence:\n",
    "        if t.lower() not in stopwords:\n",
    "            out.append(t.lower())\n",
    "    return out\n",
    "\n",
    "\n",
    "quora['q1'] = quora.lemma1.apply(lambda x: remove_stopwords(x))\n",
    "quora['q2'] = quora.lemma2.apply(lambda x: remove_stopwords(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17682 ['delete'] deleted\n",
      "35641 ['what'] What to do ?\n",
      "102512 ['ok'] ok ?\n",
      "104101 [] ?\n",
      "106577 ['what'] What?\n",
      "109311 ['what'] What\n",
      "189659 [] ?\n",
      "205947 ['deleted'] Deleted.\n",
      "216861 ['aaas'] Aaas\n",
      "249633 ['scabies'] Is this scabies?\n",
      "325200 ['error'] Error\n",
      "326297 ['how'] How\n",
      "356434 ['deleted'] Deleted.\n",
      "369529 ['who'] Who is the?\n"
     ]
    }
   ],
   "source": [
    "# Affichage des questions contenant le moins de mots-clés\n",
    "# La plupart ne sont pas valides\n",
    "ids = quora[\"id\"]\n",
    "\n",
    "for i in ids:\n",
    "    if len(quora[\"q1\"][i]) <= 1:\n",
    "        print(i, quora[\"q1\"][i], quora[\"question1\"][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Nombre de mots-clés de chaque question et différence entre les 2\n",
    "quora['lenq1'] = quora.q1.apply(lambda x: len(x))\n",
    "quora['lenq2'] = quora.q2.apply(lambda x: len(x))\n",
    "quora['diff'] = quora['lenq1'] - quora['lenq2'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Nombre de mots-clés en commun\n",
    "def words_in_common(list1, list2):\n",
    "    if len(list1)<len(list2):\n",
    "        l1 = list1\n",
    "        l2 = list2\n",
    "    else:\n",
    "        l1 = list2\n",
    "        l2 = list1\n",
    "    n = 0\n",
    "    for word in l1:\n",
    "        if word in l2:\n",
    "            n += 1\n",
    "    return n\n",
    "\n",
    "quora['nb_common_words'] = quora.apply(lambda x:words_in_common(x['q1'], x['q2']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ratio nombre de mots communs / nombre total de mots pour chaque liste de mots-clés\n",
    "def ratio_common_words(n, nt):\n",
    "    if nt == 0: # Si la question contient uniquement des stopwords\n",
    "        return 0\n",
    "    else:\n",
    "        return n/nt\n",
    "    \n",
    "quora['ratio_cw_q1'] = quora.apply(lambda x:ratio_common_words(x['nb_common_words'], x['lenq1']), axis=1)\n",
    "quora['ratio_cw_q2'] = quora.apply(lambda x:ratio_common_words(x['nb_common_words'], x['lenq2']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_obs_train  = 32343\n",
      "is_duplicate\n",
      "0    20431\n",
      "1    11912\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEUCAYAAADA7PqTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9a1aef7b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# On va d'abord diviser notre base de données en une base d'apprentissage et une base de test\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(quora, test_size = 0.2)\n",
    "\n",
    "# Nombre de paires de questions\n",
    "n_obs_train = train.shape[0]\n",
    "print(\"n_obs_train  = %d\" %n_obs_train)\n",
    "\n",
    "# Proportion de 0 et de 1\n",
    "print(train.groupby(['is_duplicate']).size())\n",
    "train.groupby(['is_duplicate']).size().plot.bar(title='train set')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_obs_test  = 8086\n",
      "is_duplicate\n",
      "0    5030\n",
      "1    3056\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEUCAYAAADN8orUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9a1af3f4e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Nombre de paires de questions\n",
    "n_obs_test = test.shape[0]\n",
    "print(\"n_obs_test  = %d\" %n_obs_test)\n",
    "\n",
    "# Proportion de 0 et de 1\n",
    "print(test.groupby(['is_duplicate']).size())\n",
    "test.groupby(['is_duplicate']).size().plot.bar(title='test set')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation des questions en vecteurs numériques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "\n",
    "def vectoriser(table):\n",
    "    dictionary = corpora.Dictionary(quora['q1'].tolist() + quora['q2'].tolist())\n",
    "    # On crée un vecteur contenant le nombre d'occurrences de chaque mot du dictionnaire pour chaque question\n",
    "    vecteur1 = [dictionary.doc2bow(text) for text in table[\"q1\"]]\n",
    "    vecteur2 = [dictionary.doc2bow(text) for text in table[\"q2\"]]\n",
    "    return vecteur1, vecteur2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim import models, similarities\n",
    "\n",
    "# Distance cosinus entre les 2 vecteurs\n",
    "vecteur1, vecteur2 = vectoriser(train)\n",
    "train['vecteur1'] = vecteur1\n",
    "train['vecteur2'] = vecteur2\n",
    "train['cosinus_dist'] = train.apply(lambda x:gensim.matutils.cossim(x['vecteur1'], x['vecteur2']), axis=1)\n",
    "\n",
    "\n",
    "t_vecteur1, t_vecteur2 = vectoriser(test)\n",
    "test['vecteur1'] = t_vecteur1\n",
    "test['vecteur2'] = t_vecteur2\n",
    "test['cosinus_dist'] = test.apply(lambda x:gensim.matutils.cossim(x['vecteur1'], x['vecteur2']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calcul du score TF-IDF score pour chaque mot\n",
    "\n",
    "corpora.MmCorpus.serialize('corpus.mm', vecteur1 + vecteur2) # Sauvegarder le corpus\n",
    "corpus1 = corpora.MmCorpus('corpus.mm') # Charger le corpus\n",
    "\n",
    "corpora.MmCorpus.serialize('t_corpus.mm', t_vecteur1 + t_vecteur2) # Sauvegarder le corpus\n",
    "t_corpus1 = corpora.MmCorpus('t_corpus.mm') # Charger le corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf = models.TfidfModel(corpus1)\n",
    "\n",
    "t_tfidf = models.TfidfModel(t_corpus1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(38, 0.1310898006489969), (62, 0.2433340485605278), (1032, 0.42482912385939764), (1113, 0.5644892055182107), (1858, 0.6515183476704434)]\n"
     ]
    }
   ],
   "source": [
    "# Exemple vecteur en utilisant le score tfidf\n",
    "corpus_tfidf = tfidf[vecteur1[0]]\n",
    "print(corpus_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train['vecteur1_Tfidf'] = train.vecteur1.apply(lambda x: tfidf[x])\n",
    "train['vecteur2_Tfidf'] = train.vecteur2.apply(lambda x: tfidf[x])\n",
    "train['cosinus_dist_Tfidf'] = train.apply(\n",
    "    lambda x:gensim.matutils.cossim(x['vecteur1_Tfidf'], x['vecteur2_Tfidf']), axis=1)\n",
    "\n",
    "test['vecteur1_Tfidf'] = test.vecteur1.apply(lambda x: t_tfidf[x])\n",
    "test['vecteur2_Tfidf'] = test.vecteur2.apply(lambda x: t_tfidf[x])\n",
    "test['cosinus_dist_Tfidf'] = test.apply(\n",
    "    lambda x:gensim.matutils.cossim(x['vecteur1_Tfidf'], x['vecteur2_Tfidf']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'qid1', 'qid2', 'question1', 'question2', 'is_duplicate', 'tokens1', 'tokens2', 'tokenspos1', 'tokenspos2', 'lemma1', 'lemma2', 'q1', 'q2', 'lenq1', 'lenq2', 'diff', 'nb_common_words', 'ratio_cw_q1', 'ratio_cw_q2', 'vecteur1', 'vecteur2', 'cosinus_dist', 'vecteur1_Tfidf', 'vecteur2_Tfidf', 'cosinus_dist_Tfidf']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>lemma1</th>\n",
       "      <th>q1</th>\n",
       "      <th>lenq1</th>\n",
       "      <th>diff</th>\n",
       "      <th>nb_common_words</th>\n",
       "      <th>ratio_cw_q1</th>\n",
       "      <th>cosinus_dist</th>\n",
       "      <th>vecteur1_Tfidf</th>\n",
       "      <th>cosinus_dist_Tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>220973</th>\n",
       "      <td>How hard is it to become a doctor?</td>\n",
       "      <td>[How, hard, be, it, to, become, a, doctor, ?]</td>\n",
       "      <td>[how, hard, it, become, doctor]</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.790569</td>\n",
       "      <td>[(38, 0.1310898006489969), (62, 0.243334048560...</td>\n",
       "      <td>0.897616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60724</th>\n",
       "      <td>Where can I get high quality promotional self-...</td>\n",
       "      <td>[Where, can, I, get, high, quality, promotiona...</td>\n",
       "      <td>[where, i, get, high, quality, promotional, se...</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>[(21, 0.12265613358890189), (86, 0.06549403059...</td>\n",
       "      <td>0.462982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169079</th>\n",
       "      <td>What are the most promising Silicon Valley sta...</td>\n",
       "      <td>[What, be, the, most, promising, Silicon, Vall...</td>\n",
       "      <td>[what, promising, silicon, valley, startup, wa...</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.676123</td>\n",
       "      <td>[(0, 0.05598333847973518), (385, 0.30969722474...</td>\n",
       "      <td>0.591185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287163</th>\n",
       "      <td>What is the cheapest, painless, easiest way to...</td>\n",
       "      <td>[What, be, the, cheapest, ,, painless, ,, easi...</td>\n",
       "      <td>[what, cheapest, painless, easiest, way, commi...</td>\n",
       "      <td>7</td>\n",
       "      <td>-3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.478091</td>\n",
       "      <td>[(0, 0.06002708253502831), (45, 0.222452909300...</td>\n",
       "      <td>0.350045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21548</th>\n",
       "      <td>What are the best places to live if one has ar...</td>\n",
       "      <td>[What, be, the, best, place, to, live, if, one...</td>\n",
       "      <td>[what, best, place, live, one, arthritis]</td>\n",
       "      <td>6</td>\n",
       "      <td>-2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.433013</td>\n",
       "      <td>[(0, 0.07218989425514374), (4, 0.1878898640351...</td>\n",
       "      <td>0.310552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                question1  \\\n",
       "220973                 How hard is it to become a doctor?   \n",
       "60724   Where can I get high quality promotional self-...   \n",
       "169079  What are the most promising Silicon Valley sta...   \n",
       "287163  What is the cheapest, painless, easiest way to...   \n",
       "21548   What are the best places to live if one has ar...   \n",
       "\n",
       "                                                   lemma1  \\\n",
       "220973      [How, hard, be, it, to, become, a, doctor, ?]   \n",
       "60724   [Where, can, I, get, high, quality, promotiona...   \n",
       "169079  [What, be, the, most, promising, Silicon, Vall...   \n",
       "287163  [What, be, the, cheapest, ,, painless, ,, easi...   \n",
       "21548   [What, be, the, best, place, to, live, if, one...   \n",
       "\n",
       "                                                       q1  lenq1  diff  \\\n",
       "220973                    [how, hard, it, become, doctor]      5    -1   \n",
       "60724   [where, i, get, high, quality, promotional, se...     11     0   \n",
       "169079  [what, promising, silicon, valley, startup, wa...      7     2   \n",
       "287163  [what, cheapest, painless, easiest, way, commi...      7    -3   \n",
       "21548           [what, best, place, live, one, arthritis]      6    -2   \n",
       "\n",
       "        nb_common_words  ratio_cw_q1  cosinus_dist  \\\n",
       "220973                4     0.800000      0.790569   \n",
       "60724                 7     0.636364      0.636364   \n",
       "169079                4     0.571429      0.676123   \n",
       "287163                4     0.571429      0.478091   \n",
       "21548                 3     0.500000      0.433013   \n",
       "\n",
       "                                           vecteur1_Tfidf  cosinus_dist_Tfidf  \n",
       "220973  [(38, 0.1310898006489969), (62, 0.243334048560...            0.897616  \n",
       "60724   [(21, 0.12265613358890189), (86, 0.06549403059...            0.462982  \n",
       "169079  [(0, 0.05598333847973518), (385, 0.30969722474...            0.591185  \n",
       "287163  [(0, 0.06002708253502831), (45, 0.222452909300...            0.350045  \n",
       "21548   [(0, 0.07218989425514374), (4, 0.1878898640351...            0.310552  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(list(train.columns.values))\n",
    "train[['question1', 'lemma1', 'q1', 'lenq1', 'diff', 'nb_common_words', 'ratio_cw_q1',\n",
    "       'cosinus_dist', 'vecteur1_Tfidf', 'cosinus_dist_Tfidf']].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lancement des classifieurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_train = train[\"is_duplicate\"]\n",
    "X_train = train[[\"diff\", \"nb_common_words\", \"lenq1\", \"lenq2\", \"ratio_cw_q1\", \"ratio_cw_q2\",\n",
    "                 \"cosinus_dist\", \"cosinus_dist_Tfidf\"]]\n",
    "\n",
    "y_test = test[\"is_duplicate\"]\n",
    "X_test = test[[\"diff\", \"nb_common_words\", \"lenq1\", \"lenq2\", \"ratio_cw_q1\", \"ratio_cw_q2\",\n",
    "               \"cosinus_dist\", \"cosinus_dist_Tfidf\"]]\n",
    "\n",
    "X_train = StandardScaler().fit_transform(X_train)\n",
    "X_test = StandardScaler().fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.670789018056\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not duplicate       0.73      0.75      0.74      5030\n",
      "    duplicate       0.57      0.54      0.55      3056\n",
      "\n",
      "  avg / total       0.67      0.67      0.67      8086\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=25)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy = \", accuracy_score(y_test, y_pred))\n",
    "#print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, target_names=[\"not duplicate\", \"duplicate\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.717783823893\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not duplicate       0.76      0.80      0.78      5030\n",
      "    duplicate       0.64      0.58      0.61      3056\n",
      "\n",
      "  avg / total       0.71      0.72      0.71      8086\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(16, 16, 8), random_state=1)\n",
    "mlp.fit(X_train, y_train)\n",
    "y_pred = mlp.predict(X_test)\n",
    "print(\"Accuracy = \", accuracy_score(y_test, y_pred))\n",
    "#print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, target_names=[\"not duplicate\", \"duplicate\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.708384862726\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not duplicate       0.75      0.80      0.77      5030\n",
      "    duplicate       0.63      0.55      0.59      3056\n",
      "\n",
      "  avg / total       0.70      0.71      0.70      8086\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=100)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(\"Accuracy = \", accuracy_score(y_test, y_pred))\n",
    "#print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, target_names=[\"not duplicate\", \"duplicate\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.707642839476\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not duplicate       0.75      0.81      0.77      5030\n",
      "    duplicate       0.63      0.55      0.59      3056\n",
      "\n",
      "  avg / total       0.70      0.71      0.70      8086\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "ada = AdaBoostClassifier(DecisionTreeClassifier(max_depth=5), algorithm=\"SAMME\", n_estimators=50)\n",
    "ada.fit(X_train, y_train)\n",
    "y_pred = ada.predict(X_test)\n",
    "print(\"Accuracy = \", accuracy_score(y_test, y_pred))\n",
    "#print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, target_names=[\"not duplicate\", \"duplicate\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse des résultats\n",
    "Les différents classifieurs obtiennent des scores assez similaires. On a fait varier les paramètres pour optimiser les résultats.\n",
    "\n",
    "On obtient des résultats substantiellement meilleurs en moyenne avec un réseau de neurones profond (MLP). Cependant, l'algorithme k-nearest neighbours offre une précision supérieure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idées d'amélioration\n",
    "- L'utilisation d'un dictionnaire de synonymes aurait pu améliorer les prédictions. En plus de compter le nombre de mots communs aux deux questions, on compte les mots synonymes.\n",
    "- Utiliser d'autres outils de classification (comme XGBoost) qui donnent de bons résultats sur ce genre de problème."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
